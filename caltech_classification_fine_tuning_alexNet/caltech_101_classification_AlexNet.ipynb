{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjrDUFzk7aYu"
      },
      "source": [
        "Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROYXKpUz6xfF",
        "outputId": "e31e44ce-f407-4c8c-9e10-4a2d7aca6f47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoqwARSw7j6I"
      },
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wp9UCADN7qUC",
        "outputId": "36fb2f9c-8b52-440a-e9ff-d065da60e8bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x794826fd2d10>"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import alexnet\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZUuo_wI8WGC"
      },
      "source": [
        "Set Arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egOvbMIc8VmF"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 101 + 1\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "LR = 1e-3\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 5e-5\n",
        "\n",
        "NUM_EPOCHS = 30\n",
        "STEP_SIZE = 20\n",
        "GAMMA = .1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-pXUqyr8dpf"
      },
      "source": [
        "Define Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rLvg7iw8sBc"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "mean = (.5, .5, .5)\n",
        "std = (.5, .5, .5)\n",
        "transform = transforms.Compose([transforms.Resize(256),\n",
        "                                transforms.CenterCrop(224),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean = mean, std = std)])\n",
        "\n",
        "eval_transform =transforms.Compose([transforms.Resize(256),\n",
        "                                     transforms.CenterCrop(224),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPAcpc6I8smt"
      },
      "source": [
        "Prepare the Data Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lM1ew3-J8wD-",
        "outputId": "853afa50-263a-40af-c779-91d098f63414"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Homework2-Caltech101'...\n",
            "remote: Enumerating objects: 9256, done.\u001b[K\n",
            "remote: Total 9256 (delta 0), reused 0 (delta 0), pack-reused 9256\u001b[K\n",
            "Receiving objects: 100% (9256/9256), 129.48 MiB | 27.70 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n",
            "Updating files: 100% (9149/9149), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone \"https://github.com/MachineLearning2020/Homework2-Caltech101.git\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xN--RRi93jF"
      },
      "outputs": [],
      "source": [
        "# this way you could run it without adding it to the notebook\n",
        "!python caltech_dataset.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH_q2onJetPe",
        "outputId": "b3c6e448-13d8-46cd-9ff5-a6857c7b463c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "airplanes\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 196, 394])"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torchvision import transforms\n",
        "split = 'train'\n",
        "\n",
        "file = open(\"/content/Homework2-Caltech101/\"+ split + \".txt\", 'r')\n",
        "lines = file.readlines()\n",
        "print(lines[100].split(\"/\")[0])\n",
        "path = \"/content/Homework2-Caltech101/101_ObjectCategories/\" + lines[100]\n",
        "image = pil_loader(path.strip())\n",
        "transform = transforms.ToTensor()\n",
        "tensor = transform(image)\n",
        "tensor.shape\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qzh9qpH4ADyY"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import VisionDataset\n",
        "from PIL import Image\n",
        "\n",
        "import os\n",
        "import os.path\n",
        "import sys\n",
        "\n",
        "def pil_loader(path):\n",
        "  with open(path, 'rb') as f:\n",
        "    img = Image.open(f)\n",
        "    return img.convert('RGB')\n",
        "\n",
        "class Caltech(VisionDataset):\n",
        "  def __init__(self, root, split = 'train', transform = None, target_transform = None):\n",
        "    super(Caltech, self).__init__(root, transform = transform, target_transform=target_transform)\n",
        "    self.split = split\n",
        "    self.root = root\n",
        "    self.transform = transform\n",
        "    self.image_dict = {}\n",
        "    self.class_dict = {}\n",
        "\n",
        "    split = 'train'\n",
        "\n",
        "    file = open(\"/content/Homework2-Caltech101/\"+ split + \".txt\", 'r')\n",
        "    lines = file.readlines()\n",
        "    index = 0\n",
        "    class_index = 0\n",
        "    for line in lines:\n",
        "      path = self.root + line\n",
        "      label = line.split(\"/\")[0]\n",
        "      if label not in self.class_dict.keys():\n",
        "        self.class_dict[label] = class_index\n",
        "        self.image_dict[index] = (pil_loader(path.strip()),class_index)\n",
        "        class_index += 1\n",
        "      else:\n",
        "        target_class = self.class_dict[label]\n",
        "        self.image_dict[index] = (pil_loader(path.strip()),target_class)\n",
        "\n",
        "      index += 1\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image, label = self.image_dict[index]\n",
        "    if self.transform is not None:\n",
        "      image = self.transform(image)\n",
        "    return image, label\n",
        "  def __len__(self):\n",
        "    return len(self.image_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb4xCx5BkNmZ",
        "outputId": "6ef1638a-c860-496b-ddf5-e376b922a3dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Homework2-Caltech101\n",
            "fatal: destination path 'Homework2-Caltech101' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "import pathlib\n",
        "print(pathlib.Path().resolve())\n",
        "if not os.path.isdir('./Caltech101'):\n",
        "  !git clone https://github.com/MachineLearning2020/Homework2-Caltech101.git\n",
        "\n",
        "DATA_DIR = \"/content/Homework2-Caltech101/101_ObjectCategories/\"\n",
        "\n",
        "training_data = Caltech(DATA_DIR, 'train', transform = transform)\n",
        "test_data = Caltech(DATA_DIR, 'test', transform = eval_transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aljthES5Y7h"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(training_data, batch_size = BATCH_SIZE, shuffle = True, drop_last=True)\n",
        "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XigKNL5h7Cfc"
      },
      "source": [
        "Preparing the Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGjvco_f6cQB"
      },
      "outputs": [],
      "source": [
        "net = alexnet()\n",
        "net.classifier[6] = nn.Linear(4096, NUM_CLASSES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CeloP3j8YEQ"
      },
      "source": [
        "Prepare for Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q-tkasW8YYL",
        "outputId": "01a49c2a-41f8-4594-b566-701cee2a2e2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "parameters_to_optimize = net.parameters()\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr = LR , momentum = MOMENTUM, weight_decay= WEIGHT_DECAY )\n",
        "\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = STEP_SIZE, gamma = GAMMA)\n",
        "print(len(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgD7qK8wALSQ",
        "outputId": "04b97a74-af5b-44c1-b924-33750c582a39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss of step:  0 is:  tensor(4.6245, grad_fn=<NllLossBackward0>)\n",
            "loss of step:  10 is:  tensor(4.6232, grad_fn=<NllLossBackward0>)\n",
            "loss of step:  20 is:  tensor(4.6214, grad_fn=<NllLossBackward0>)\n",
            "loss of step:  30 is:  tensor(4.6198, grad_fn=<NllLossBackward0>)\n",
            "loss of step:  40 is:  tensor(4.6161, grad_fn=<NllLossBackward0>)\n",
            "loss of step:  50 is:  tensor(4.6150, grad_fn=<NllLossBackward0>)\n",
            "loss of step:  60 is:  tensor(4.6126, grad_fn=<NllLossBackward0>)\n",
            "loss of step:  70 is:  tensor(4.6036, grad_fn=<NllLossBackward0>)\n",
            "loss of step:  80 is:  tensor(4.6040, grad_fn=<NllLossBackward0>)\n",
            "loss of step:  90 is:  tensor(4.5993, grad_fn=<NllLossBackward0>)\n",
            "loss of step:  100 is:  tensor(4.5961, grad_fn=<NllLossBackward0>)\n",
            "loss of step:  110 is:  tensor(4.5988, grad_fn=<NllLossBackward0>)\n",
            "loss of step:  120 is:  tensor(4.5956, grad_fn=<NllLossBackward0>)\n",
            "loss of step:  130 is:  tensor(4.5909, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "current_step = 0\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  for images, labels in train_loader:\n",
        "    net.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    if current_step % 10 == 0:\n",
        "      print(\"loss of step: \", current_step,\"is: \", loss )\n",
        "    current_step += 1\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  scheduler.step()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}